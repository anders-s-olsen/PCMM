{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PCMM.mixture_EM_loop import mixture_EM_loop\n",
    "from PCMM.mixture_torch_loop import mixture_torch_loop\n",
    "from PCMM.helper_functions import calc_NMI\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on Phase Coherence Mixture Modeling (PCMM)\n",
    "\n",
    "When dealing with multivariate narrowband data, such as those from functional neuroimaging modalities such as fMRI, EEG, or MEG, it is useful to model the instantaneous phase coherence between channels as a proxy for instantaneous correlation. This toolbox provides several ways to model such data, though we refer to our paper for all the details: https://www.biorxiv.org/content/10.1101/2024.11.15.623830v1.\n",
    "\n",
    "In this tutorial, we will demonstrate how to use the toolbox to simulate phase coherence data and fit a K-means, mixture, or HMM. We will use simulated data corresponding to K=2 true components with consistent phase shifts and added noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = np.pi*2/3\n",
    "num_points_per_cluster = 1000\n",
    "p = 3 # Data dimensionality\n",
    "q = 2 # Number of frames for grassmann data\n",
    "K = 2 # Number of true clusters\n",
    "\n",
    "# True thetas\n",
    "theta1 = np.array([0,np.pi/2,0]) \n",
    "theta2 = np.array([0,0,np.pi/2]) \n",
    "thetas = [theta1,theta2]\n",
    "\n",
    "data_real_projective_hyperplane = np.zeros((num_points_per_cluster,p,K))\n",
    "data_complex_projective_hyperplane = np.zeros((num_points_per_cluster,p,K),dtype=complex) \n",
    "data_grassmann = np.zeros((num_points_per_cluster,p,q,K)) \n",
    "data_spsd = np.zeros((num_points_per_cluster,p,q,K))\n",
    "data_ts = np.zeros((num_points_per_cluster,p,K))\n",
    "\n",
    "true_labels = np.zeros((K,num_points_per_cluster*2))\n",
    "true_labels[0,num_points_per_cluster:] = 1\n",
    "true_labels[1,:num_points_per_cluster] = 1\n",
    "\n",
    "for n in range(num_points_per_cluster):\n",
    "    for k in range(K):\n",
    "        theta_plus_noise = thetas[k]+np.random.random(3)*noise_scale-noise_scale/2\n",
    "\n",
    "        #timeseries\n",
    "        data_ts[n,:,k] = np.cos(theta_plus_noise)\n",
    "\n",
    "        # eigenvector of cosinus matrix\n",
    "        coh_map = np.outer(np.cos(theta_plus_noise),np.cos(theta_plus_noise))+np.outer(np.sin(theta_plus_noise),np.sin(theta_plus_noise))\n",
    "        l,u = np.linalg.eig(coh_map)\n",
    "        order = np.argsort(l)[::-1]\n",
    "        data_real_projective_hyperplane[n,:,k] = u[:,order[0]]\n",
    "        data_grassmann[n,:,:,k] = u[:,order[:q]]\n",
    "        data_spsd[n,:,:,k] = u[:,order[:q]]*np.sqrt(l[order[:q]])[None]\n",
    "\n",
    "        # eigenvector of complex coherence matrix\n",
    "        coh_map_complex = np.outer(np.exp(1j*theta_plus_noise),np.exp(-1j*theta_plus_noise))\n",
    "        l,u = np.linalg.eig(coh_map_complex)\n",
    "        order = np.argsort(l)[::-1]\n",
    "        data_complex_projective_hyperplane[n,:,k] = u[:,order[0]]\n",
    "\n",
    "# concatenate data over the last dimension\n",
    "data_ts = np.concatenate([data_ts[:,:,0],data_ts[:,:,1]],axis=0)\n",
    "data_real_projective_hyperplane = np.concatenate([data_real_projective_hyperplane[:,:,0],data_real_projective_hyperplane[:,:,1]],axis=0)\n",
    "data_complex_projective_hyperplane = np.concatenate([data_complex_projective_hyperplane[:,:,0],data_complex_projective_hyperplane[:,:,1]],axis=0)\n",
    "data_grassmann = np.concatenate([data_grassmann[:,:,:,0],data_grassmann[:,:,:,1]],axis=0)\n",
    "data_spsd = np.concatenate([data_spsd[:,:,:,0],data_spsd[:,:,:,1]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a Pandas DataFrame to collect all results. Columns should be 'model', 'manifold', 'init', 'HMM', numpy/torch, 'NMI'\n",
    "df = pd.DataFrame(columns=['model', 'manifold', 'init', 'HMM', 'numpy/torch', 'NMI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means models\n",
    "\n",
    "K-means models here include the following:\n",
    "- Least squares K-means whereupon input eigenvectors are sign-flipped such that the majority of elements are negative\n",
    "- Diametrical clustering\n",
    "- Complex diametrical clustering\n",
    "- Grassmann clustering\n",
    "- Weighted Grassmann clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2 # Number of estimated components\n",
    "max_iter = 10000 # Maximum number of iterations\n",
    "init = '++' # Initialization method ('uniform' or '++')\n",
    "tol = 1e-10 # Tolerance for the convergence criterion\n",
    "num_repl = 2 # Number of estimates to choose the best from (different initializations)\n",
    "from PCMM.phase_coherence_kmeans import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-means models output the cluster centers, data partition vector, and objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_ls,X_part_ls,obj = least_squares_sign_flip(data_real_projective_hyperplane, K,max_iter=max_iter,init=init,tol=tol,num_repl=num_repl)\n",
    "C_dc,X_part_dc,obj = diametrical_clustering(data_real_projective_hyperplane, K,max_iter=max_iter,init=init,tol=tol,num_repl=num_repl)\n",
    "C_cdc,X_part_cdc,obj = diametrical_clustering(data_complex_projective_hyperplane, K,max_iter=max_iter,init=init,tol=tol,num_repl=num_repl)\n",
    "C_gc,X_part_gc,obj = grassmann_clustering(data_grassmann, K,max_iter=max_iter,init=init,tol=tol,num_repl=num_repl)\n",
    "C_wgc,X_part_wgc,obj = weighted_grassmann_clustering(data_spsd, K,max_iter=max_iter,init=init,tol=tol,num_repl=num_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares on sign-flipped leading eigenvectors: NMI=0.16220547294931656\n",
      "Diametrical clustering on real projective hyperplane: NMI=0.14342238974110763\n",
      "Diametrical clustering on complex projective hyperplane: NMI=0.7938573675374688\n",
      "Grassmann clustering: NMI=0.12163509412433136\n",
      "Weighted Grassmann clustering: NMI=0.24772033459036275\n"
     ]
    }
   ],
   "source": [
    "print('Least squares on sign-flipped leading eigenvectors: NMI='+str(calc_NMI(true_labels,np.eye(K)[X_part_ls].T)))\n",
    "print('Diametrical clustering on real projective hyperplane: NMI='+str(calc_NMI(true_labels,np.eye(K)[X_part_dc].T)))\n",
    "print('Diametrical clustering on complex projective hyperplane: NMI='+str(calc_NMI(true_labels,np.eye(K)[X_part_cdc].T)))\n",
    "print('Grassmann clustering: NMI='+str(calc_NMI(true_labels,np.eye(K)[X_part_gc].T)))\n",
    "print('Weighted Grassmann clustering: NMI='+str(calc_NMI(true_labels,np.eye(K)[X_part_wgc].T)))\n",
    "df = pd.DataFrame({'model': ['Least squares on sign-flipped leading eigenvectors', 'Diametrical clustering', 'Complex diametrical clustering', 'Grassmann clustering', 'Weighted Grassmann clustering'],\n",
    "                     'manifold': ['Real projective hyperplane', 'Real projective hyperplane', 'Complex projective hyperplane', 'Grassmann', 'Grassmann'],\n",
    "                        'init': [init, init, init, init, init],\n",
    "                        'HMM': [False, False, False, False, False],\n",
    "                        'numpy/torch': ['numpy', 'numpy', 'numpy', 'numpy', 'numpy'],\n",
    "                        'rank': [1,1,1,2,2],\n",
    "                        'NMI': [calc_NMI(true_labels,np.eye(K)[X_part_ls].T), calc_NMI(true_labels,np.eye(K)[X_part_dc].T), calc_NMI(true_labels,np.eye(K)[X_part_cdc].T), calc_NMI(true_labels,np.eye(K)[X_part_gc].T), calc_NMI(true_labels,np.eye(K)[X_part_wgc].T)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture models, numpy estimation (EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancing a mixture model\n",
    "The implemented statistical distributions are:\n",
    "- Watson (rank-1 component)\n",
    "- Angular central Gaussian (ACG) (rank-r component)\n",
    "- Matrix angular central Gaussian (MACG) (rank-r component)\n",
    "- Singular Wishart (rank-r component)\n",
    "- Gaussian (rank-r component)\n",
    "\n",
    "Of these, Watson and ACG are for data on the (complex) projective hyperplane, i.e., the input data vectors should be normalized to unit norm. MACG is for data on the Grassmann manifold, i.e., the input data should be orthonormal matrices. Singular Wishart is for symmetric positive semidefinite matrices, i.e., the input data should be matrices corresponding to eigenvectors scaled by the square root of their eigenvalues. \n",
    "\n",
    "In our implementation, a mixture model first has to be instanced with some required inputs:\n",
    "- K: number of components\n",
    "- p: data dimensionality (e.g,. number of brain regions)\n",
    "- q: number of orthonormal frames (only applicable to MACG and Singular Wishart)\n",
    "\n",
    "Furthermore, the model instance hold the following optional inputs:\n",
    "- rank [None]: The desired component rank (not applicable to Watson, which estimates a rank-1 component). Defaults to a full-rank model.\n",
    "- complex [False]: Whether the distribution should be for complex data (only applicable to Watson and ACG)\n",
    "- params [None]: Initial parameters for the model. Should be formatted the same way as for a model output.\n",
    "\n",
    "### Estimating the model\n",
    "For model estimation, we have made a training loop available, which has the following required inputs:\n",
    "- model: The mixture model instance\n",
    "- data: The input data as a numpy array of either shape (n, p) (projective hyperplane) or (n, p, q) (Grassmann or SPSD) depending on the model\n",
    "\n",
    "The training loop has the following optional inputs:\n",
    "- max_iter [10000]: Maximum number of iterations\n",
    "- tol [1e-8]: Tolerance for convergence\n",
    "- num_repl [1]: Number of restarts to choose the best model from\n",
    "- init [None]: Initial parameters for the model. Options are 'uniform' for randomly initialized parameters, 'ls', 'dc', 'gc', and 'wgc' for K-means initialization as above, 'dc++', 'gc++', and 'wgc++' for K-means++ initialization, and 'ls_seg', 'dc_seg', 'gc_seg', and 'wgc_seg' for K-means followed by K single-component estimates. \n",
    "\n",
    "For initialization, note that 'dc' can be applied for Grassmann data and SPSD data, in that case, only the first column of the orthonormal matrices are used. Oppositely, 'gc' and 'wgc' cannot be used for projective hyperplane data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters applying to all methods\n",
    "max_iter = 10000 # Maximum number of iterations\n",
    "tol = 1e-10 # Tolerance for the convergence criterion\n",
    "params = None # Initial set of parameters\n",
    "num_repl = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 6.16e-11:   0%|          | 37/10000 [00:00<01:59, 83.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 6.16e-11:   0%|          | 38/10000 [00:00<01:59, 83.53it/s]\n",
      "Convergence towards tol: 5.96e-11:   0%|          | 31/10000 [00:00<01:54, 87.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson mixture model (real): NMI=0.15172924684348932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Watson mixture model (real)\n",
    "from PCMM.PCMMnumpy import Watson\n",
    "model = Watson(K=K, p=p, complex=False, params=None)\n",
    "init = 'dc' # initialization with diametrical clustering (which is itself seeded by dc++)\n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_real_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('Watson mixture model (real): NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Watson mixture', 'manifold': 'Real projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': 1, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.06e-11:   0%|          | 18/10000 [00:00<02:39, 62.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.06e-11:   0%|          | 19/10000 [00:00<02:45, 60.21it/s]\n",
      "Convergence towards tol: 4.11e-11:   0%|          | 20/10000 [00:00<02:58, 55.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson mixture model (complex): NMI=0.8410397418471373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Watson mixture model (complex)\n",
    "from PCMM.PCMMnumpy import Watson\n",
    "model = Watson(K=K, p=p, complex=True, params=None)\n",
    "init = 'dc' # initialization with diametrical clustering (which is itself seeded by dc++)\n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_complex_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('Watson mixture model (complex): NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Watson mixture', 'manifold': 'Complex projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': 1, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In the initial phase:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.06e-11:   0%|          | 50/10000 [00:00<01:02, 158.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.06e-11:   1%|          | 51/10000 [00:00<00:50, 195.15it/s]\n",
      "Convergence towards tol: 8.98e-11:   0%|          | 41/10000 [00:00<00:51, 191.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACG mixture model (real): NMI=0.08051159317954622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ACG mixture model (real)\n",
    "rank=2\n",
    "from PCMM.PCMMnumpy import ACG\n",
    "model = ACG(K=K, p=p, rank=rank, complex=False, params=None)\n",
    "init = 'dc' \n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_real_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('ACG mixture model (real): NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'ACG mixture', 'manifold': 'Real projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 7.77e-07:   0%|          | 14/10000 [00:00<01:04, 155.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 7.77e-07:   0%|          | 15/10000 [00:00<01:09, 144.64it/s]\n",
      "Convergence towards tol: 1.34e-07:   0%|          | 15/10000 [00:00<01:11, 140.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACG mixture model (complex): NMI=0.7595278456175755\n"
     ]
    }
   ],
   "source": [
    "# ACG mixture model (complex)\n",
    "rank=2\n",
    "from PCMM.PCMMnumpy import ACG\n",
    "model = ACG(K=K, p=p, rank=rank, complex=True, params=None)\n",
    "init = 'dc' \n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_complex_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('ACG mixture model (complex): NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'ACG mixture', 'manifold': 'Complex projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.84e-11:   0%|          | 24/10000 [00:02<06:31, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.84e-11:   0%|          | 25/10000 [00:02<17:22,  9.57it/s]\n",
      "Convergence towards tol: 4.91e-10:   0%|          | 22/10000 [00:02<19:36,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACG mixture model: NMI=1.1761810459819492e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MACG mixture model\n",
    "from PCMM.PCMMnumpy import MACG\n",
    "rank = 2\n",
    "model = MACG(K=K, p=p, q=2, rank=rank, params=None)\n",
    "init = 'gc'\n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_grassmann, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('MACG mixture model: NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'MACG mixture', 'manifold': 'Grassmann', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running weighted grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.09e-11:   1%|          | 110/10000 [00:01<01:47, 91.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running weighted grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning EM loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 8.09e-11:   1%|          | 111/10000 [00:01<01:50, 89.48it/s]\n",
      "Convergence towards tol: 9.81e-11:   1%|          | 113/10000 [00:01<02:03, 80.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Wishart model: NMI=0.0704905507094566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Singular Wishart model\n",
    "from PCMM.PCMMnumpy import SingularWishart\n",
    "rank = 2\n",
    "model = SingularWishart(K=K, p=p, q=2, rank=rank, params=None)\n",
    "init = 'wgc'\n",
    "params, posterior, loglik = mixture_EM_loop(\n",
    "    model=model, data=data_spsd, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init\n",
    ")\n",
    "print('Singular Wishart model: NMI='+str(calc_NMI(true_labels,posterior)))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Singular Wishart', 'manifold': 'Grassmann', 'init': init, 'HMM': False, 'numpy/torch': 'numpy', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model estimation in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture estimation in PyTorch can be very fruitful for large datasets, both because of the possibility to run on GPUs and since EM estimation often requires intensive loops for each iteration. The PyTorch implementation is very similar to the numpy implementation, but with the following differences:\n",
    "\n",
    "### Instancing a mixture model\n",
    "A mixture model now has the option to also include a HMM and a samples_per_sequence parameter:\n",
    "- HMM [False]: Whether the model should be a Hidden Markov Model\n",
    "- samples_per_sequence [0]: Number of samples per sequence in the HMM to avoid temporal smoothing over sequences. If 0, it is assumed to be one sequence. If int, it is assumed to be N/samples_per_sequence sequences. Otherwise it can be a list. \n",
    "- For ACG, MACG, Singular Wishart, and Gaussian, the `rank` parameter is now required.\n",
    "\n",
    "### Estimating the model\n",
    "The training loop has the following additional optional inputs:\n",
    "- LR [0.1]: Learning rate for the optimizer\n",
    "- decrease_lr_on_plateau [False]: Whether the learning rate should decrease by a factor of 10 once when tol has been reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters applying to all methods\n",
    "max_iter = 10000 # Maximum number of iterations\n",
    "tol = 1e-10 # Tolerance for the convergence criterion\n",
    "params = None # Initial set of parameters\n",
    "LR = 0.1 # Learning rate\n",
    "num_repl = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 6.33e-06:   4%|▍         | 434/10000 [00:12<05:10, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 6.33e-06:   4%|▍         | 435/10000 [00:12<04:29, 35.44it/s]\n",
      "Convergence towards tol: 2.20e-06:   6%|▌         | 554/10000 [00:16<04:47, 32.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson mixture model (real): NMI=0.15874834151182368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Watson mixture model (real)\n",
    "from PCMM.PCMMtorch import Watson # Note the torch!\n",
    "model = Watson(K=K, p=p, complex=False, params=None, HMM=False)\n",
    "init = 'dc' \n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_real_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('Watson mixture model (real): NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Watson mixture', 'manifold': 'Real projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': 1, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 2.65e-09:   3%|▎         | 315/10000 [00:07<04:27, 36.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing mu based on the clustering centroid\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 2.65e-09:   3%|▎         | 315/10000 [00:07<04:05, 39.40it/s]\n",
      "Convergence towards tol: 1.67e-07:   2%|▏         | 214/10000 [00:05<04:23, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson mixture model (complex): NMI=0.8410788344626612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Watson mixture model (complex)\n",
    "from PCMM.PCMMtorch import Watson\n",
    "model = Watson(K=K, p=p, complex=True, params=None, HMM=False)\n",
    "init = 'dc' # initialization with diametrical clustering (which is itself seeded by dc++)\n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_complex_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('Watson mixture model (complex): NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Watson mixture', 'manifold': 'Complex projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': 1, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 9.90e-11:   8%|▊         | 824/10000 [00:03<00:34, 269.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 9.90e-11:   8%|▊         | 825/10000 [00:03<00:34, 268.95it/s]\n",
      "Convergence towards tol: 9.95e-11:   5%|▌         | 519/10000 [00:03<01:03, 148.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACG mixture model (real): NMI=0.1764080594348394\n"
     ]
    }
   ],
   "source": [
    "# ACG mixture model (real)\n",
    "rank=2\n",
    "from PCMM.PCMMtorch import ACG\n",
    "model = ACG(K=K, p=p, rank=rank, complex=False, params=None, HMM=False)\n",
    "init = 'dc' \n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_real_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('ACG mixture model (real): NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'ACG mixture', 'manifold': 'Real projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 2.90e-12:   2%|▏         | 165/10000 [00:00<00:42, 229.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diametrical clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 2.90e-12:   2%|▏         | 166/10000 [00:00<00:44, 219.90it/s]\n",
      "Convergence towards tol: 2.22e-04:   0%|          | 20/10000 [00:00<01:00, 164.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACG mixture model (complex): NMI=0.7752507210523177\n"
     ]
    }
   ],
   "source": [
    "# ACG mixture model (complex)\n",
    "rank=2\n",
    "from PCMM.PCMMtorch import ACG\n",
    "model = ACG(K=K, p=p, rank=rank, complex=True, params=None, HMM=False)\n",
    "init = 'dc' \n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_complex_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('ACG mixture model (complex): NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'ACG mixture', 'manifold': 'Complex projective hyperplane', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM\n",
    "It's always a good idea to initialize HMMs from a learned mixture model. In this case, remember to set init='no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 5.64e-08:   7%|▋         | 701/10000 [08:25<1:51:47,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACG mixture model (complex): NMI=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ACG mixture model (complex, HMM)\n",
    "rank=2\n",
    "from PCMM.PCMMtorch import ACG\n",
    "import copy\n",
    "model = ACG(K=K, p=p, rank=rank, complex=True, params=copy.deepcopy(params), HMM=True)\n",
    "init = 'no' \n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_complex_projective_hyperplane, \n",
    "    tol=tol, max_iter=max_iter, num_repl=1, init=init, LR=LR\n",
    ")\n",
    "print('ACG mixture model (complex): NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'ACG mixture', 'manifold': 'Complex projective hyperplane', 'init': init, 'HMM': True, 'numpy/torch': 'torch', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In the initial phase:   0%|          | 6/10000 [00:00<02:31, 65.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 9.97e-11:   5%|▍         | 497/10000 [00:06<02:03, 77.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 9.97e-11:   5%|▍         | 498/10000 [00:06<02:04, 76.33it/s]\n",
      "Convergence towards tol: 9.98e-11:   5%|▌         | 501/10000 [00:07<02:18, 68.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACG mixture model: NMI=0.2344825294017614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MACG mixture model\n",
    "from PCMM.PCMMtorch import MACG\n",
    "rank = 2\n",
    "model = MACG(K=K, p=p, q=2, rank=rank, params=None, HMM=False)\n",
    "init = 'gc'\n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_grassmann, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('MACG mixture model: NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'MACG mixture', 'manifold': 'Grassmann', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running weighted grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 5.83e-08:   2%|▏         | 200/10000 [00:01<00:56, 174.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running weighted grassmann clustering initialization\n",
      "Initializing M based on a lowrank-svd of the input data partitioned acc to the clustering\n",
      "Beginning numerical optimization loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convergence towards tol: 5.83e-08:   2%|▏         | 201/10000 [00:01<00:56, 172.02it/s]\n",
      "Convergence towards tol: 1.44e-05:   2%|▏         | 165/10000 [00:01<01:17, 126.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Wishart model: NMI=0.07468450672559256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Singular Wishart model\n",
    "from PCMM.PCMMtorch import SingularWishart\n",
    "rank = 2\n",
    "model = SingularWishart(K=K, p=p, q=2, rank=rank, params=None, HMM=False)\n",
    "init = 'wgc'\n",
    "params, posterior, loglik = mixture_torch_loop(\n",
    "    model=model, data=data_spsd, \n",
    "    tol=tol, max_iter=max_iter, num_repl=num_repl, init=init, LR=LR\n",
    ")\n",
    "print('Singular Wishart model: NMI='+str(calc_NMI(true_labels,posterior.numpy())))\n",
    "df = pd.concat([df,pd.DataFrame({'model': 'Singular Wishart', 'manifold': 'Grassmann', 'init': init, 'HMM': False, 'numpy/torch': 'torch', 'rank': rank, 'NMI': [calc_NMI(true_labels,posterior.numpy())]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the results below. If interested, try changing the noise scale in the second cell to see what changes. The data generated is from a mixture of rank-1 true components, and thus, complex diametrical clustering and Watson mixtures perform well below, with no added advantage of ACG. All other models are unable to model consistent phase shifts well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>manifold</th>\n",
       "      <th>init</th>\n",
       "      <th>HMM</th>\n",
       "      <th>numpy/torch</th>\n",
       "      <th>rank</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Least squares on sign-flipped leading eigenvec...</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>++</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diametrical clustering</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>++</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex diametrical clustering</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>++</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grassmann clustering</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>++</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weighted Grassmann clustering</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>++</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Watson mixture</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Watson mixture</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACG mixture</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACG mixture</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MACG mixture</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>gc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Singular Wishart</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>wgc</td>\n",
       "      <td>False</td>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Watson mixture</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Watson mixture</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACG mixture</td>\n",
       "      <td>Real projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACG mixture</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>dc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ACG mixture</td>\n",
       "      <td>Complex projective hyperplane</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>torch</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MACG mixture</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>gc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Singular Wishart</td>\n",
       "      <td>Grassmann</td>\n",
       "      <td>wgc</td>\n",
       "      <td>False</td>\n",
       "      <td>torch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0   Least squares on sign-flipped leading eigenvec...   \n",
       "1                              Diametrical clustering   \n",
       "2                      Complex diametrical clustering   \n",
       "3                                Grassmann clustering   \n",
       "4                       Weighted Grassmann clustering   \n",
       "5                                      Watson mixture   \n",
       "6                                      Watson mixture   \n",
       "7                                         ACG mixture   \n",
       "8                                         ACG mixture   \n",
       "9                                        MACG mixture   \n",
       "10                                   Singular Wishart   \n",
       "11                                     Watson mixture   \n",
       "12                                     Watson mixture   \n",
       "13                                        ACG mixture   \n",
       "14                                        ACG mixture   \n",
       "15                                        ACG mixture   \n",
       "16                                       MACG mixture   \n",
       "17                                   Singular Wishart   \n",
       "\n",
       "                         manifold init    HMM numpy/torch  rank    NMI  \n",
       "0      Real projective hyperplane   ++  False       numpy     1  0.162  \n",
       "1      Real projective hyperplane   ++  False       numpy     1  0.143  \n",
       "2   Complex projective hyperplane   ++  False       numpy     1  0.794  \n",
       "3                       Grassmann   ++  False       numpy     2  0.122  \n",
       "4                       Grassmann   ++  False       numpy     2  0.248  \n",
       "5      Real projective hyperplane   dc  False       numpy     1  0.152  \n",
       "6   Complex projective hyperplane   dc  False       numpy     1  0.841  \n",
       "7      Real projective hyperplane   dc  False       numpy     2  0.081  \n",
       "8   Complex projective hyperplane   dc  False       numpy     2  0.760  \n",
       "9                       Grassmann   gc  False       numpy     2  0.000  \n",
       "10                      Grassmann  wgc  False       numpy     2  0.070  \n",
       "11     Real projective hyperplane   dc  False       torch     1  0.159  \n",
       "12  Complex projective hyperplane   dc  False       torch     1  0.841  \n",
       "13     Real projective hyperplane   dc  False       torch     2  0.176  \n",
       "14  Complex projective hyperplane   dc  False       torch     2  0.775  \n",
       "15  Complex projective hyperplane   no   True       torch     2  1.000  \n",
       "16                      Grassmann   gc  False       torch     2  0.234  \n",
       "17                      Grassmann  wgc  False       torch     2  0.075  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NMI'] = df['NMI'].apply(lambda x: '{:.3f}'.format(x))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
